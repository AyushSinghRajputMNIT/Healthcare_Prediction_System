1.	Load Dataset:
1.1.	Load synthetic_health_data.csv, containing health metrics and associated health issues, into a DataFrame.
1.2.	Separate the features (X) and labels (y) for model training.
2.	Balance Dataset Using SMOTE:
2.1.	Apply SMOTE (Synthetic Minority Over-sampling Technique) to the features and labels to balance classes and avoid bias toward more frequent health issues.
3.	Split Dataset:
3.1.	Split the balanced data into training and testing sets, with 20% reserved for testing.
4.	Hyperparameter Tuning Using GridSearchCV:
4.1.	Define a grid of parameters to optimize the RandomForestClassifier model.
4.2.	Use GridSearchCV with a five-fold cross-validation approach, optimizing for weighted F1 score.
4.3.	Fit RandomForestClassifier with class weights balanced to handle any minor class imbalances.
5.	Select Best Model:
5.1.	Obtain the best model based on cross-validation results from GridSearchCV.
5.2.	Use this model to make predictions on the test set.
6.	Save Model:
6.1.	Save the trained model as health_model.pkl for future use.
